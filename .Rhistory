summary(lm)
plot(trainFaith$waiting, trainFaith$eruption, col="red", pch=19)
abline(lm, col="blue", lwd=2)
plot(faithful$waiting, faithful$eruption, col="red", pch=19)
abline(fit0, col="blue", lwd=2)
testPre<-predict(lm, newdata=testFaith)
plot(trainFaith$waiting, trainFaith$eruption, col="red", pch=19)
abline(lm, col="blue", lwd=2)
plot(testFaith$waiting, fitted(testPre), col="red", pch=19)
testPre
plot(testFaith$waiting, testPre, col="red", pch=19)
plot(testFaith$waiting, fitted(testPre), col="red", pch=19)
plot(trainFaith$waiting, trainFaith$eruption, col="red", pch=19)
abline(lm, col="blue", lwd=2)
plot(testFaith$waiting, testFaith$eruption, col="red", pch=19)
line(testFaith$waiting, testPre, col="blue", type="l", lwd=2)
line(testFaith$waiting, testPre, col="blue", lwd=2)
line(testFaith$waiting, testPre)
lines(testFaith$waiting, testPre, col="blue", lwd=2)
abline(lm(eruption ~ waiting, data=testFaith), col="black", lwd=2)
abline(lm(eruptions ~ waiting, data=testFaith), col="black", lwd=2)
sqrt(sum((fitted(lm) - trainFaith$eruption)^2))
deviance(fit0)
deviance(lm)
library(ISLR)
install.packages("ISLR")
library(ISLR)
data(Wages)
data(wages)
?ISLR
?data(ISLR)
data()
data(Wgae)
data(Wage)
str(Wage)
MatrCor<-cor(Wage[is.numeric(Wage)])
MatrCor
MatrCor<-cor(Wage[,is.numeric(Wage)])
MatrCor
is.numeric(Wage)
is.numeric(Wage[,])
is.numeric(Wage[1])
is.numeric(Wage[2])
is.numeric(Wage[,2])
is.numeric(Wage[])
MatrCor<-cor(Wage[,c(1,2,11,12))
MatrCor<-cor(Wage[,c(1,2,11,12)])
MatrCor
summary(Wage)
training<-createDataPartition(Wage$wage,p=0.7, list=FALSE)
library(caret)
training<-createDataPartition(Wage$wage,p=0.7, list=FALSE)
inTrain<-createDataPartition(Wage$wage,p=0.7, list=FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
dim(training)
dim(testing)
data(iris); library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
library(caret)
data(iris); library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
library(caret)
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit
modFit$finalModel
names(modFit)
modFit$pred
modFit$results
table(testing$Species, predict(modFit, newdata=testing))
print(modFit)
modFit[[1]]
modFit[[2]]
modFit[[4]]
modFit[[3]]
modFit
names(modFit)
modFit$modelInfo
names(modFit)
modFit$modelType
modFit$results
modFit$pred
modFit$bestTune
modFit$call
modFit$dots
modFit$metric
modFit$control
names(modFit)
modFit$finalModel
modFit$terms
names(modFit)
modFit$xlevels
modFit$xlevels[1]
modFit$xlevels[[1]]
modFit$xlevels[2]
modFit
getTree(modFit$finalModel,k=2)
getTree(modFit$finalModel,k=3)
getTree(modFit$finalModel,k=1)
getTree(modFit$finalModel,k=4)
getTree(modFit$finalModel,k=41)
getTree(modFit$finalModel,k=501)
getTree(modFit$finalModel,k=500)
getTree(modFit$finalModel,k=1)
getTree(modFit$finalModel,k=2)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit)
plot(modFit)
fancyRFPlot(modFit)
modFit$finalModel$prox
tail(modFit$finalModel$prox)
getTree(modFit$finalModel,k=2)
predict(getTree(modFit$finalModel,k=2), newdata=testing[1])
importance(modFit)
library(randomforest)
library(randomForest)
importance(modFit)
modRF<-randomforest(Speies ~ ., data=training)
modRF<-randomForest(Speies ~ ., data=training)
modRF<-randomForest(Species ~ ., data=training)
rm(modRF)
fit.rf<-randomForest(Species ~ ., data=training)
print(fit.rf)
importance(fit.rf)
plot(fit.rf)
plot( importance(fit.rf), lty=2, pch=16)
lines(importance(fit.rf))
imp = importance(fit.rf)
impvar = rownames(imp)[order(imp[, 1], decreasing=TRUE)]
op = par(mfrow=c(1, 3))
for (i in seq_along(impvar)) {
partialPlot(fit.rf, raw, impvar[i], xlab=impvar[i],
main=paste("Partial Dependence on", impvar[i]),
ylim=c(0, 1))
}
imp
plot_by_factor<-function(index)
{
rownames(imp)
impvar
for (i in seq_along(impvar)) {
+     partialPlot(fit.rf, raw, impvar[i], xlab=impvar[i],
+                 main=paste("Partial Dependence on", impvar[i]),
+                 ylim=c(0, 1))
+ }
for (i in seq_along(impvar)) {
+     partialPlot(fit.rf, raw, impvar[i], xlab=impvar[i],main=paste("Partial Dependence on", impvar[i]),ylim=c(0, 1))}
getTree(modFit$finalModel,k=2)
getTree(modFit$finalModel,k=2, label.var=TRUE)
getTree(modFit$finalModel,k=2, labelvar=TRUE)
getTree(modFit$finalModel,k=2, label_var=TRUE)
getTree(modFit$finalModel,k=2, labelVar=TRUE)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
library(rpart)
model<-rpart(Area ~., data=olive, method="class")
predict(model, newdata=newdata, type = "class")
predict(model, newdata=newdata)
predict(model, newdata=newdata, type="class")
predict(model, newdata=newdata, type="default")
predict(model, newdata=newdata, type="class")
predict(model, newdata=newdata)
newdata
predict(model, newdata=newdata, type="class")
predict(model, newdata=newdata,type = c("prob"))
model1<-tree(Area ~., data=olive)
library(tree)
model1<-tree(Area ~., data=olive)
predict(model1, newdata=newdata,type = c("prob"))
predict(model1, newdata=newdata,type = "class"
)
predict(model1, newdata=newdata,type = "tree")
predict(model1, newdata=newdata,type = "vector")
predict(model1, newdata=newdata,type = "where")
predict(model1, newdata=newdata)
library(caret)
library(ElemStatLearn)
install.packagesl("ElemStatLearn")
install.packages("ElemStatLearn")
library(ElemStatLearn)
str(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
mod1.rf<-train(y ~., data=vowel.train, method="rf")
mod.gbm<-train(y ~., data=vowel.train, method="gbm")
print(mod.rf)
print(mod1.rf)
print(mod.gbm)
dim(vaowel.test)
data(vowel.test)
dim(vaowel.test)
dim(vowel.test)
pre.rf<-predict(mod1.rf, newdata=vowel.test, type="class")
pre.rf<-predict(mod1.rf, newdata=vowel.test, type="raw")
pre.gbm<-predict(mod.gbm, newdata=vowel.test, type="raw")
confusionMatrix(vowel.test$y, pre.rf)
confusionMatrix(vowel.test$y, pre.gbm)
confusionMatrix(vowel.test$y, pre.gbm)$Accuracy
str(confusionMatrix(vowel.test$y, pre.gbm))
confusionMatrix(vowel.test$y, pre.gbm)$overall["Accuracy"]
c(confusionMatrix(vowel.test$y, pre.rf)$overall["Accuracy"], confusionMatrix(vowel.test$y, pre.gbm)$overall["Accuracy"])
pre.rf<-predict(mod1.rf, newdata=vowel.test, type="raw")
agree<-pre.rf==pre.gbm
sub.test<-subset(vowel.test, agree)
agree
rm(sub.test)
c(confusionMatrix(vowel.test$y[agree], pre.rf[agree])$overall["Accuracy"], confusionMatrix(vowel.test$y[agree], pre.gbm[agree])$overall["Accuracy"])
sum(agree)
sum(agree)/length(vowel.test)
sum(agree)/dim(vowel.test)[1]
set.seed(33833)
mod.rf<-train(y ~., data=vowel.train, method="rf")
set.seed(33833)
mod.gbm<-train(y ~., data=vowel.train, method="gbm", verbose=FALSE)
pre.rf<-predict(mod.rf, newdata=vowel.test, type="raw")
pre.gbm<-predict(mod.gbm, newdata=vowel.test, type="raw")
c(confusionMatrix(vowel.test$y, pre.rf)$overall["Accuracy"], confusionMatrix(vowel.test$y, pre.gbm)$overall["Accuracy"])
agree<-pre.rf==pre.gbm
c(confusionMatrix(vowel.test$y[agree], pre.rf[agree])$overall["Accuracy"], confusionMatrix(vowel.test$y[agree], pre.gbm[agree])$overall["Accuracy"])
mean(agree)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod.rf1<-train(diagnosis ~., data=training, method="rf")
mod.gbm1<-train(diagnosis ~., data=training, method="gbm")
mod.1da<-train(diagnosis ~., data=training, method="lda")
pred.rf1<-predict(mod.rf1, newdata=testing, type="raw")
pred.gbm1<-predict(mod.gbm1, newdata=testing, type="raw")
pred.lda<-predict(mod.lda, newdata=testing, type="raw")
mod.lda<-mod.1da
pred.lda<-predict(mod.lda, newdata=testing, type="raw")
pred.rf1<-predict(mod.rf1, newdata=training, type="raw")
pred.gbm1<-predict(mod.gbm1, newdata=training, type="raw")
pred.lda1<-predict(mod.lda, newdata=training, type="raw")
pred.df<-data.frame(pred.rf1, pred.gbm1, pred.lda, training$diagnosis)
pred.df<-data.frame(pred.rf1, pred.gbm1, pred.lda1, training$diagnosis)
pred.df
pred.df<-data.frame(pred.rf1, pred.gbm1, pred.lda1, diagnosis=training$diagnosis)
pred.df
mod.stacked<-train(diagnosis ~., data=pred.df, method="rf")
pred.test<-predict(mod.stacked, newdata=testing, type="raw")
summary(mod.stacked)
head(pred.df)
tail(pred.df)
dim(training)
dim(testing)
dim(pred.df)
mod.stacked<-train(diagnosis ~., data=pred.df, method="rf")
print(mod.stacked)
pred.rf1.test<-predict(mod.rf1, newdata=testing, type="raw")
pred.gbm1.test<-predict(mod.gbm1, newdata=testing, type="raw")
pred.lda1.test<-predict(mod.lda, newdata=testing, type="raw")
pred.df.test<-data.frame(pred.rf1.test, pred.gbm1.test, pred.lda1.test, diagnosis=testing$diagnosis)
pred.stacked<-predict(mod.stacked, newdata=testing, type="raw")
pred.rf1.test
dim(pred.rf1.test)
length(pred.rf1.test)
length(pred.gbm1.test)
length(pred.lda1.test)
dim(pred.df.test)
pred.stacked<-predict(mod.stacked, newdata=pred.df.test, type="raw")
mod.stacked<-train(diagnosis ~., data=pred.df, method="gam")
pred.rf1.test<-predict(mod.rf1, newdata=testing, type="raw")
pred.gbm1.test<-predict(mod.gbm1, newdata=testing, type="raw")
pred.lda1.test<-predict(mod.lda, newdata=testing, type="raw")
pred.df.test<-data.frame(pred.rf1.test, pred.gbm1.test, pred.lda1.test, diagnosis=testing$diagnosis)
pred.stacked<-predict(mod.stacked, newdata=pred.df.test, type="raw")
pred.df.test
print(mod.stacked)
mod.stacked<-train(diagnosis ~., data=pred.df, method="rf")
print(mod.stacked)
print(mod.rf1)
pred.rf1.test<-predict(mod.rf1, newdata=testing, type="raw")
pred.gbm1.test<-predict(mod.gbm1, newdata=testing, type="raw")
pred.lda1.test<-predict(mod.lda, newdata=testing, type="raw")
pred.df.test<-data.frame(pred.rf1.test, pred.gbm1.test, pred.lda1.test, diagnosis=testing$diagnosis)
pred.stacked<-predict(mod.stacked, newdata=pred.df.test, type="raw")
confusionMatrix(testing$diagnosis, pred.stacked)
length(pred.stacked)
length(pred.rf1.test)
length(pred.gbm1.test)
length(pred.lda1.test)
length(testing$diagnosis)
dim(pred.df)
dim(pred.df.test)
pred.stacked<-predict(mod.stacked, newdata=pred.rf1.test, type="raw")
mod.stacked<-train(diagnosis ~., data=pred.df, method="rf")
pred.rf1<-predict(mod.rf1, newdata=testing, type="raw")
pred.gbm1<-predict(mod.gbm1, newdata=testing, type="raw")
pred.lda1<-predict(mod.lda, newdata=testing, type="raw")
pred.df<-data.frame(pred.rf1, pred.gbm1, pred.lda1, diagnosis=testing$diagnosis)
mod.stacked<-train(diagnosis ~., data=pred.df, method="rf")
pred.stacked<-predict(mod.stacked, newdata=pred.df, type="raw")
dim(pred.stacked)
length(pred.stacked)
confusionMatrix(testing$diagnosis, pred.stacked)
confusionMatrix(testing$diagnosis, pred.stacked)$overall["Accuracy"]
Acc.stacked<-confusionMatrix(testing$diagnosis, pred.stacked)$overall["Accuracy"]
Acc.rf1<-confusionMatrix(testing$diagnosis, pred.rf1)$overall["Accuracy"]
Acc.gbm1<-confusionMatrix(testing$diagnosis, pred.gbm1)$overall["Accuracy"]
Acc.lda1<-confusionMatrix(testing$diagnosis, pred.lda1)$overall["Accuracy"]
cbind(Acc.rf1, Acc.gbm1, Acc.lda1, Acc.stacked)
set.seed(62433)
set.seed(62433)
mod.rf1<-train(diagnosis ~., data=training, method="rf", trControl=trainContro(method="cv"), n=3)
set.seed(62433)
mod.gbm1<-train(diagnosis ~., data=training, method="gbm", verbose=FALSE)
set.seed(62433)
mod.lda<-train(diagnosis ~., data=training, method="lda")
et.seed(62433)
mod.rf1<-train(diagnosis ~., data=training, method="rf", trControl=trainControl(method="cv"), n=3)
set.seed(62433)
mod.gbm1<-train(diagnosis ~., data=training, method="gbm", verbose=FALSE)
set.seed(62433)
mod.lda<-train(diagnosis ~., data=training, method="lda")
set.seed(62433)
mod.rf1<-train(diagnosis ~., data=training, method="rf", trControl=trainControl(method="cv"), number=3)
set.seed(62433)
mod.gbm1<-train(diagnosis ~., data=training, method="gbm", verbose=FALSE)
set.seed(62433)
mod.lda<-train(diagnosis ~., data=training, method="lda")
pred.rf1<-predict(mod.rf1, newdata=testing, type="raw")
pred.gbm1<-predict(mod.gbm1, newdata=testing, type="raw")
pred.lda1<-predict(mod.lda, newdata=testing, type="raw")
## use the predictions on testing set to build the stacked model
pred.df<-data.frame(pred.rf1, pred.gbm1, pred.lda1, diagnosis=testing$diagnosis)
mod.stacked<-train(diagnosis ~., data=pred.df, method="rf")
pred.stacked<-predict(mod.stacked, newdata=pred.df, type="raw")
Acc.stacked<-confusionMatrix(testing$diagnosis, pred.stacked)$overall["Accuracy"]
Acc.rf1<-confusionMatrix(testing$diagnosis, pred.rf1)$overall["Accuracy"]
Acc.gbm1<-confusionMatrix(testing$diagnosis, pred.gbm1)$overall["Accuracy"]
Acc.lda1<-confusionMatrix(testing$diagnosis, pred.lda1)$overall["Accuracy"]
cbind(Acc.rf1, Acc.gbm1, Acc.lda1, Acc.stacked)
set.seed(62433)
mod.stacked<-train(diagnosis ~., data=pred.df, method="rf")
pred.stacked<-predict(mod.stacked, newdata=pred.df, type="raw")
Acc.stacked<-confusionMatrix(testing$diagnosis, pred.stacked)$overall["Accuracy"]
Acc.rf1<-confusionMatrix(testing$diagnosis, pred.rf1)$overall["Accuracy"]
Acc.gbm1<-confusionMatrix(testing$diagnosis, pred.gbm1)$overall["Accuracy"]
Acc.lda1<-confusionMatrix(testing$diagnosis, pred.lda1)$overall["Accuracy"]
cbind(Acc.rf1, Acc.gbm1, Acc.lda1, Acc.stacked)
set.seed(62433)
mod.stacked<-train(diagnosis ~., data=pred.df, method="rf", trControl=trainControl(method="cv"), number=3)
pred.stacked<-predict(mod.stacked, newdata=pred.df, type="raw")
Acc.stacked<-confusionMatrix(testing$diagnosis, pred.stacked)$overall["Accuracy"]
Acc.rf1<-confusionMatrix(testing$diagnosis, pred.rf1)$overall["Accuracy"]
Acc.gbm1<-confusionMatrix(testing$diagnosis, pred.gbm1)$overall["Accuracy"]
Acc.lda1<-confusionMatrix(testing$diagnosis, pred.lda1)$overall["Accuracy"]
cbind(Acc.rf1, Acc.gbm1, Acc.lda1, Acc.stacked)
install.packages("AppliedPredictiveModeling")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
mod.lasso<-train(CompressiveStrength ~., data=training, method="lasso")
mod.lasso<-train(CompressiveStrength ~., data=training, method="lasso")
plot.enet(mod.lasso)
?plot.enet
?enet
plot.enet(enet(concrete[mod.lasso)
str(concrete)
plot.enet(enet(concrete[1:8], concrete[9]))
enet(concrete[1:8], concrete[9])
enet(concrete[1:8], concrete[9], lambda=0)
enet(as.matrix(concrete[1:8]), concrete[9], lambda=0)
enet(concrete[1]), concrete[9], lambda=0)
enet(concrete[,1]), concrete[,9], lambda=0)
enet(concrete[,1]), concrete[,9] lambda=0)
enet(concrete[,1]) concrete[,9] lambda=0)
enet(concrete[, 1]), concrete[, 9], lambda=0)
x<-concrete[,1]
y<-concrete[,9]
enet(x, y, lambda=0)
x
y
enet(x, y, lambda=0)
mod.lasso<-train(CompressiveStrength ~., data=training, method="lasso")
print(mod.lasso)
x<-as.matrix(training[,1:8])
x
y<-training[,9]
head(y)
head(x)
enet(x, y, lambda=0)
plot.enet(enet(x, y, lambda=0))
plot(mod.lasso)
print(mod.lasso)
plot.enet(enet(x, y, lambda=0))
enet(x, y, lambda=0,intercept = T)
str(training)
lm1<-lm(CompressiveStrength ~., data=training)
summary(lm1)
?plot.enet
print(mod.lasso)
names(mod.lasso)
mod.lasso$pred
mod.lasso$modelInfo
names(mod.lasso)
mod.lasso$perfNames
mod.lasso$results
summary(mod.lasso)
enet(x, y, lambda=0)
plot.enet(enet(x, y, lambda=0))
plot(mod.lasso)
84/96
89/94
x<-c(89, 72, 94, 69)
x-mean(x)
(x-mean(x))/range(x)
8/25
range(x)
range(x)[2]-range(x)[1]
(x-mean(x))/(range(x)[2]-range(x)[1])
shiny::runApp('Dropbox/DataSpecialization/Exercises_Quizes/09_DevelopingDataProducts/App3')
library(devttols)
library(devtools)
install.packages('stringr')
devtools::install_github('muschellij2/slidify')
setwd("~/BigData/datasciencecoursera/09_DevelopingDataProducts/MyProjectPitch")
slidify("index.Rmd")
library(slidify)
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
pop<-read.csv("../DataProductProject/PopolazionePerComuneEdAnno.csv")
str(pop)
pop$X
pop$X<-NULL
pop$X
str(pop)
write.csv(pop, "../DataProductProject/PopolazionePerComuneEdAnno.csv", row.names = FALSE)
pop<-read.csv("../DataProductProject/PopolazionePerComuneEdAnno.csv")
str(pop)
setwd("~/BigData/datasciencecoursera/09_DevelopingDataProducts/DataProductProject")
runApp()
library(shiny)
runApp()
setwd("~/BigData/datasciencecoursera/09_DevelopingDataProducts/MyProjectPitch")
slidify("index.Rmd")
pop<-read.csv("../DataProductProject/PopolazionePerComuneEdAnno.csv")
str(pop)
slidify("index.Rmd")
browseURL("index.Rmd")
browseURL("index.html")
filename<-"../DataProductProject/PopolazionePerComuneEdAnno.csv"
PopEtaAnno<-read.csv(filename, stringsAsFactors = FALSE)
summary(PopEtaAnno)
slidify("index.Rmd")
summary(PopEtaAnno)
filename<-"../DataProductProject/PopolazionePerComuneEdAnno.csv"
PopEtaAnno<-read.csv(filename, stringsAsFactors = FALSE)
summary(PopEtaAnno)
print(towns<-sort(unique(PopEtaAnno$Comune)))
summary(PopEtaAnno)
slidify("index.Rmd")
browseURL("index.html")
summary(PopEtaAnno)
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
